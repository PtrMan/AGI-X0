<#@ template debug="false" hostspecific="false" language="C#" #>
<#@ assembly name="System.Core" #>
<#@ import namespace="System.Linq" #>
<#@ import namespace="System.Text" #>
<#@ import namespace="System.Collections.Generic" #>
<#@ output extension=".cs" #>

// AUTOGENERATED
// Classes for specific neural network implementations

<#
	IList<Tuple<string, string, bool, bool>> networkConfigurations = new List<Tuple<string, string, bool, bool>>(){
		new Tuple<string, string, bool, bool>("PermutationExp", "return Activation.exp(v);", true, false),
		new Tuple<string, string, bool, bool>("IdentityTanh", "return Activation.tanh(v);", false, false),
		new Tuple<string, string, bool, bool>("IdentityExp", "return Activation.exp(v);", false, false),
		new Tuple<string, string, bool, bool>("IdentityElu", "return Activation.elu(v, alpha);", false, false),
		new Tuple<string, string, bool, bool>("IdentityVariable", "switch(neuronProperties.activationFunction) {case GeneralNeuronProperties.EnumActivationFunction.TANH: return Activation.tanh(v);case GeneralNeuronProperties.EnumActivationFunction.ELU: return Activation.elu(v, alpha);case GeneralNeuronProperties.EnumActivationFunction.EXP: return Activation.exp(v); default: throw new System.Exception();}", false, true),
	};	
#>

namespace AiThisAndThat {
	public abstract class GeneralNeuronProperties {
	    public float[] weights;

        public float[] permutatedInput; // temporary preallocated array
        //public float[] weightedInputs; // temporary preallocated array

        public float resultValue;

		public float bias;

		public enum EnumActivationFunction {
			TANH,
			EXP,
			ELU,
		}
	}

	public abstract class GeneralFeedForwardNeuralNetwork<NeuronPropertiesType>
	:
		IForwardPropagatableNetwork,
		IWeightedNetwork, 
		IHasResult<float>
	where NeuronPropertiesType : GeneralNeuronProperties
	{
		public float alpha; // might not get used

        public Layer<NeuronPropertiesType>[] layers;

		protected float[] activationOfPreviousLayer;

		public int numberOfWeights { get {
			int number = 0;
			foreach( var iLayer in layers )
				foreach( var iNeuron in iLayer.neurons )
					number += iNeuron.weights.Length;

			return number;
		}}

		public void updateWeights(float[] weights) {
			int i = 0;

			foreach( var iLayer in layers )
				foreach( var iNeuron in iLayer.neurons )
					for( int j = 0; j < iNeuron.weights.Length; j++ )
						iNeuron.weights[j] = weights[i++];
		}

		public float[] result { get {
			var lastLayer = layers[layers.Length-1];

			float[] arr = new float[lastLayer.neurons.Length];
			for( int idx = 0; idx < lastLayer.neurons.Length; idx++ ) {
				arr[idx] = lastLayer.neurons[idx].resultValue;
			}

			return arr;
		}}
		
		// virtual to keep open to modification by inherited class
		virtual public void forwardPropagate(float[] input) {
			storeInputAsActivationOfPreviousLayer(input);

            foreach( var iLayer in layers ) {
                updateNeuronsOfLayer(iLayer);
                storeActivationOfNeuronsAsActivationOfPreviousLayer(iLayer);
            }
		}

		// abstract because virtual call overhead is low enougth
		protected abstract void updateNeuronsOfLayer(Layer<NeuronPropertiesType> layer);

		protected void storeActivationOfNeuronsAsActivationOfPreviousLayer(Layer<NeuronPropertiesType> layer) {
            activationOfPreviousLayer = new float[layer.neurons.Length];
            for( int idx = 0; idx < layer.neurons.Length; idx++ )
                activationOfPreviousLayer[idx] = layer.neurons[idx].resultValue;
        }

        protected void storeInputAsActivationOfPreviousLayer(float[] input) {
            activationOfPreviousLayer = input;
        }

	}

	<# foreach( var iNetworkConfiguration in networkConfigurations ) { #>

    public class NeuronProperties<#=iNetworkConfiguration.Item1#> : GeneralNeuronProperties {
        <# if(iNetworkConfiguration.Item3) #>public int[] srcIndices; <#;#>

		<# if(iNetworkConfiguration.Item4) #>public EnumActivationFunction activationFunction; <#;#>
    }
    
    public class NeuralNetwork<#=iNetworkConfiguration.Item1#> :
		GeneralFeedForwardNeuralNetwork< NeuronProperties<#=iNetworkConfiguration.Item1#> >
	
	{
        // network specific, AUTOGENERATED
        float neuronActivation(NeuronProperties<#=iNetworkConfiguration.Item1#> neuronProperties, float v) {
            <#=iNetworkConfiguration.Item2#>
		}

        // network specific, AUTOGENERATED
        static void inputPermutation(float[] activationOfPreviousLayer, NeuronProperties<#=iNetworkConfiguration.Item1#> neuronProperties) {
            <# if(iNetworkConfiguration.Item3) { #>Permutation.permutation(activationOfPreviousLayer, ref neuronProperties.permutatedInput, neuronProperties.srcIndices);
			<#}#>
			<# if(!iNetworkConfiguration.Item3) {#>Permutation.identity(activationOfPreviousLayer, ref neuronProperties.permutatedInput);
			<#}#>

        }

        void updateNeuron(NeuronProperties<#=iNetworkConfiguration.Item1#> neuronProperties) {
            // permutate the input as required
            // we do this to support sparse neural networks
            inputPermutation(activationOfPreviousLayer, neuronProperties);
            
            float v = NeuralNetworkMath.dot(neuronProperties.permutatedInput, neuronProperties.weights);
			v += neuronProperties.bias;
            float activation = neuronActivation(neuronProperties, v);
            neuronProperties.resultValue = activation;
        }

        protected override void updateNeuronsOfLayer(Layer<NeuronProperties<#=iNetworkConfiguration.Item1#>> layer) {
            for( int idx = 0; idx < layer.neurons.Length; idx++ )  updateNeuron(layer.neurons[idx]);
        }
    }

<#}#>
}
