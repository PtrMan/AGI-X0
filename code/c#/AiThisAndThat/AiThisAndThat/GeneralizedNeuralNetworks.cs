
// AUTOGENERATED
// Classes for specific neural network implementations


namespace AiThisAndThat {
	public abstract class GeneralNeuronProperties {
	    public float[] weights;

        public float[] permutatedInput; // temporary preallocated array
        //public float[] weightedInputs; // temporary preallocated array

        public float resultValue;

		public float bias;

		public enum EnumActivationFunction {
			TANH,
			EXP,
			ELU,
		}
	}

	public abstract class GeneralFeedForwardNeuralNetwork<NeuronPropertiesType>
	:
		IForwardPropagatableNetwork,
		IWeightedNetwork,
        IBiasedNetwork,
		IHasResult<float>
	where NeuronPropertiesType : GeneralNeuronProperties
	{
		public float alpha; // might not get used

        public Layer<NeuronPropertiesType>[] layers;

		protected float[] activationOfPreviousLayer;

		public int numberOfWeights { get {
			int number = 0;
			foreach( var iLayer in layers )
				foreach( var iNeuron in iLayer.neurons )
					number += iNeuron.weights.Length;

			return number;
		}}

		public void updateWeights(float[] weights) {
			int i = 0;

			foreach( var iLayer in layers )
				foreach( var iNeuron in iLayer.neurons ) {
					for( int j = 0; j < iNeuron.weights.Length; j++ )
						iNeuron.weights[j] = weights[i++];
                }
		}

        public int numberOfBiases { get {
            int number = 0;
			foreach( var iLayer in layers )
				foreach( var iNeuron in iLayer.neurons )
					number++;

			return number;
        } }

        public void updateBiases(float[] biases) {
            int i = 0;

			foreach( var iLayer in layers )
				foreach( var iNeuron in iLayer.neurons )
                    iNeuron.bias = biases[i++];
        }


		public float[] result { get {
			var lastLayer = layers[layers.Length-1];

			float[] arr = new float[lastLayer.neurons.Length];
			for( int idx = 0; idx < lastLayer.neurons.Length; idx++ ) {
				arr[idx] = lastLayer.neurons[idx].resultValue;
			}

			return arr;
		}}
		
		// virtual to keep open to modification by inherited class
		virtual public void forwardPropagate(float[] input) {
			storeInputAsActivationOfPreviousLayer(input);

            foreach( var iLayer in layers ) {
                updateNeuronsOfLayer(iLayer);
                storeActivationOfNeuronsAsActivationOfPreviousLayer(iLayer);
            }
		}

		// abstract because virtual call overhead is low enougth
		protected abstract void updateNeuronsOfLayer(Layer<NeuronPropertiesType> layer);

		protected void storeActivationOfNeuronsAsActivationOfPreviousLayer(Layer<NeuronPropertiesType> layer) {
            activationOfPreviousLayer = new float[layer.neurons.Length];
            for( int idx = 0; idx < layer.neurons.Length; idx++ )
                activationOfPreviousLayer[idx] = layer.neurons[idx].resultValue;
        }

        protected void storeInputAsActivationOfPreviousLayer(float[] input) {
            activationOfPreviousLayer = input;
        }

	}

	
    public class NeuronPropertiesPermutationExp : GeneralNeuronProperties {
        public int[] srcIndices; 
		    }
    
    public class NeuralNetworkPermutationExp :
		GeneralFeedForwardNeuralNetwork< NeuronPropertiesPermutationExp >
	
	{
        // network specific, AUTOGENERATED
        float neuronActivation(NeuronPropertiesPermutationExp neuronProperties, float v) {
            return Activation.exp(v);
		}

        // network specific, AUTOGENERATED
        static void inputPermutation(float[] activationOfPreviousLayer, NeuronPropertiesPermutationExp neuronProperties) {
            Permutation.permutation(activationOfPreviousLayer, ref neuronProperties.permutatedInput, neuronProperties.srcIndices);
						
        }

        void updateNeuron(NeuronPropertiesPermutationExp neuronProperties) {
            // permutate the input as required
            // we do this to support sparse neural networks
            inputPermutation(activationOfPreviousLayer, neuronProperties);
            
            float v = NeuralNetworkMath.dot(neuronProperties.permutatedInput, neuronProperties.weights);
			v += neuronProperties.bias;
            float activation = neuronActivation(neuronProperties, v);
            neuronProperties.resultValue = activation;
        }

        protected override void updateNeuronsOfLayer(Layer<NeuronPropertiesPermutationExp> layer) {
            for( int idx = 0; idx < layer.neurons.Length; idx++ )  updateNeuron(layer.neurons[idx]);
        }
    }


    public class NeuronPropertiesIdentityTanh : GeneralNeuronProperties {
        
		    }
    
    public class NeuralNetworkIdentityTanh :
		GeneralFeedForwardNeuralNetwork< NeuronPropertiesIdentityTanh >
	
	{
        // network specific, AUTOGENERATED
        float neuronActivation(NeuronPropertiesIdentityTanh neuronProperties, float v) {
            return Activation.tanh(v);
		}

        // network specific, AUTOGENERATED
        static void inputPermutation(float[] activationOfPreviousLayer, NeuronPropertiesIdentityTanh neuronProperties) {
            			Permutation.identity(activationOfPreviousLayer, ref neuronProperties.permutatedInput);
			
        }

        void updateNeuron(NeuronPropertiesIdentityTanh neuronProperties) {
            // permutate the input as required
            // we do this to support sparse neural networks
            inputPermutation(activationOfPreviousLayer, neuronProperties);
            
            float v = NeuralNetworkMath.dot(neuronProperties.permutatedInput, neuronProperties.weights);
			v += neuronProperties.bias;
            float activation = neuronActivation(neuronProperties, v);
            neuronProperties.resultValue = activation;
        }

        protected override void updateNeuronsOfLayer(Layer<NeuronPropertiesIdentityTanh> layer) {
            for( int idx = 0; idx < layer.neurons.Length; idx++ )  updateNeuron(layer.neurons[idx]);
        }
    }


    public class NeuronPropertiesIdentityExp : GeneralNeuronProperties {
        
		    }
    
    public class NeuralNetworkIdentityExp :
		GeneralFeedForwardNeuralNetwork< NeuronPropertiesIdentityExp >
	
	{
        // network specific, AUTOGENERATED
        float neuronActivation(NeuronPropertiesIdentityExp neuronProperties, float v) {
            return Activation.exp(v);
		}

        // network specific, AUTOGENERATED
        static void inputPermutation(float[] activationOfPreviousLayer, NeuronPropertiesIdentityExp neuronProperties) {
            			Permutation.identity(activationOfPreviousLayer, ref neuronProperties.permutatedInput);
			
        }

        void updateNeuron(NeuronPropertiesIdentityExp neuronProperties) {
            // permutate the input as required
            // we do this to support sparse neural networks
            inputPermutation(activationOfPreviousLayer, neuronProperties);
            
            float v = NeuralNetworkMath.dot(neuronProperties.permutatedInput, neuronProperties.weights);
			v += neuronProperties.bias;
            float activation = neuronActivation(neuronProperties, v);
            neuronProperties.resultValue = activation;
        }

        protected override void updateNeuronsOfLayer(Layer<NeuronPropertiesIdentityExp> layer) {
            for( int idx = 0; idx < layer.neurons.Length; idx++ )  updateNeuron(layer.neurons[idx]);
        }
    }


    public class NeuronPropertiesIdentityElu : GeneralNeuronProperties {
        
		    }
    
    public class NeuralNetworkIdentityElu :
		GeneralFeedForwardNeuralNetwork< NeuronPropertiesIdentityElu >
	
	{
        // network specific, AUTOGENERATED
        float neuronActivation(NeuronPropertiesIdentityElu neuronProperties, float v) {
            return Activation.elu(v, alpha);
		}

        // network specific, AUTOGENERATED
        static void inputPermutation(float[] activationOfPreviousLayer, NeuronPropertiesIdentityElu neuronProperties) {
            			Permutation.identity(activationOfPreviousLayer, ref neuronProperties.permutatedInput);
			
        }

        void updateNeuron(NeuronPropertiesIdentityElu neuronProperties) {
            // permutate the input as required
            // we do this to support sparse neural networks
            inputPermutation(activationOfPreviousLayer, neuronProperties);
            
            float v = NeuralNetworkMath.dot(neuronProperties.permutatedInput, neuronProperties.weights);
			v += neuronProperties.bias;
            float activation = neuronActivation(neuronProperties, v);
            neuronProperties.resultValue = activation;
        }

        protected override void updateNeuronsOfLayer(Layer<NeuronPropertiesIdentityElu> layer) {
            for( int idx = 0; idx < layer.neurons.Length; idx++ )  updateNeuron(layer.neurons[idx]);
        }
    }


    public class NeuronPropertiesIdentityVariable : GeneralNeuronProperties {
        
		public EnumActivationFunction activationFunction;     }
    
    public class NeuralNetworkIdentityVariable :
		GeneralFeedForwardNeuralNetwork< NeuronPropertiesIdentityVariable >
	
	{
        // network specific, AUTOGENERATED
        float neuronActivation(NeuronPropertiesIdentityVariable neuronProperties, float v) {
            switch(neuronProperties.activationFunction) {case GeneralNeuronProperties.EnumActivationFunction.TANH: return Activation.tanh(v);case GeneralNeuronProperties.EnumActivationFunction.ELU: return Activation.elu(v, alpha);case GeneralNeuronProperties.EnumActivationFunction.EXP: return Activation.exp(v); default: throw new System.Exception();}
		}

        // network specific, AUTOGENERATED
        static void inputPermutation(float[] activationOfPreviousLayer, NeuronPropertiesIdentityVariable neuronProperties) {
            			Permutation.identity(activationOfPreviousLayer, ref neuronProperties.permutatedInput);
			
        }

        void updateNeuron(NeuronPropertiesIdentityVariable neuronProperties) {
            // permutate the input as required
            // we do this to support sparse neural networks
            inputPermutation(activationOfPreviousLayer, neuronProperties);
            
            float v = NeuralNetworkMath.dot(neuronProperties.permutatedInput, neuronProperties.weights);
			v += neuronProperties.bias;
            float activation = neuronActivation(neuronProperties, v);
            neuronProperties.resultValue = activation;
        }

        protected override void updateNeuronsOfLayer(Layer<NeuronPropertiesIdentityVariable> layer) {
            for( int idx = 0; idx < layer.neurons.Length; idx++ )  updateNeuron(layer.neurons[idx]);
        }
    }

}
